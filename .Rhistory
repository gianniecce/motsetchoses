dtaPP %>% group_by(id, day) %>% summarise(max(Time))
```
which means that we have created a one minute interval dataset, known as **Long Person-Period**:
This code enables to transform the long file into a **Wide Sequence** file.
```{r}
dtaWide = dtaPP %>% select(-epnum) %>% spread(Time, activities)
```
The 10 first sequence episodes look like this :
```{r, results='asis', echo=FALSE}
kable( dtaWide [, 1:12] , align = 'c')
```
dta
l = length(dta$duration)
v = array(0, l)
l
for(i in 1:l){
v[i] = gcd(dta$duration[i], dta$duration[i+1])
}
min(v)
dta$duration
dta$duration
for(i in 1:l){
v[i] = gcd(dta$duration[i], dta$duration[i+1])
}
for(i in 2:l){
v[i] = gcd(dta$duration[i], dta$duration[i-1])
}
min(v)
v
?gcd
dta$duration
dtaPP = dta[rep(1:nrow(dta), dta$duration), ] %>%
select(-duration) %>%
group_by(id, day) %>%
mutate( Time = 1:n())
```{r}
dtaPP %>% group_by(id, day) %>% summarise(max(Time))
72 * 20
dtaPP = dta[rep(1:nrow(dta), dta$duration), ] %>%
select(-duration) %>%
group_by(id, day) %>%
mutate( Time = 1:n())
servr::jekyll(command = '/Users/giacomovagni/.rvm/gems/ruby-2.2.1/wrappers/jekyll build')
---
layout: post
title:  "Data Format"
categories: [jekyll]
tags: [mtus]
---
<span class='newthought'>This post</span> will demonstrate how to simply calcualte mean time of different activities from a *wide format* dataset.
- Load the libraries and data
```{r, warning=FALSE, message=FALSE}
library(plyr)
library(dplyr)
library(tidyr)
library(mtusRlocal)
library(knitr)
library(reshape2)
library(xtable)
library('schoolmath')
dta = read.csv('/Users/giacomovagni/site/motsetchoses/_data/dtaSpells.csv')
```
```{r, results='asis', echo=FALSE}
kable(dta, align = 'c')
```
```{r}
dtaPP = dta[rep(1:nrow(dta), dta$duration), ] %>%
select(-duration) %>%
group_by(id, day) %>%
mutate( Time = 1:n())
```
Let's look at the first 10 entries
```{r, results='asis', echo=FALSE}
kable(dtaPP [1:10, ], align = 'c')
```
The maximum time per day is
```{r}
dtaPP %>% group_by(id, day) %>% summarise(max(Time))
```
which means that we have created a one minute interval dataset, known as **Long Person-Period**:
This code enables to transform the long file into a **Wide Sequence** file.
```{r}
dtaWide = dtaPP %>% select(-epnum) %>% spread(Time, activities)
```
The 10 first sequence episodes look like this :
```{r, results='asis', echo=FALSE}
kable( dtaWide [, 1:12] , align = 'c')
```
## Change the interval time
Find the greatest common divisor
```{r}
l = length(dta$duration)
v = array(0, l)
for(i in 2:l){
v[i] = gcd(dta$duration[i], dta$duration[i-1])
}
min(v)
v
v
for(i in 2:l){
v[i] = gcd(dta$duration[i-1], dta$duration[i])
}
min(v)
v
dta$duration
gcd(4, 4)
gcd(100, 100)
gcd
gcd(500, 400)
gcd(400, 500)
for(i in 2:l){
v[i] = gcd(dta$duration[i-1], dta$duration[i])
}
min(v)
v
for(i in 2:l){
v[i] = gcd(dta$duration[i], dta$duration[i-1])
}
min(v)
v
dta$duration
l = length(dta$duration) - 1
v = array(0, l)
for(i in 2:l){
v[i] = gcd(dta$duration[i], dta$duration[i-1])
}
v
for(i in 2:l){
v[i] = gcd(dta$duration[i-1], dta$duration[i])
}
v
l = length(dta$duration)
v = array(0, l)
for(i in 2:l){
v[i] = gcd(dta$duration[i-1], dta$duration[i])
}
v
lag(dta$duration)
head(dta$duration)
dta$duration
dta$duration - head(dta$duration)
dta$duration
head(dta$duration)
gcd( dta$duration, head(dta$duration) )
l = length(dta$duration)
v = array(0, l)
dta$duration[2-1]
dta$duration[2]
dta$duration[3-1]
for(i in 2:l){
v[i] = gcd(dta$duration[i], dta$duration[i])
}
v
dta$duration
for(i in 2:l){
v[i] = gcd(dta$duration[i], dta$duration[i+1])
}
v
for(i in 2:l){
v[i] = gcd(dta$duration[i], dta$duration[i-1])
}
v
dta$duration
min(v[-1])
minV = min(v[-1])
dta$duration = dta$duration / minV
```{r}
l = length(dta$duration)
v = array(0, l)
for(i in 2:l){
v[i] = gcd(dta$duration[i], dta$duration[i-1])
}
minV = min(v[-1])
dta$duration = dta$duration / minV
```
```{r}
dtaPP = dta[rep(1:nrow(dta), dta$duration), ] %>%
select(-duration) %>%
group_by(id, day) %>%
mutate( Time = 1:n())
```
The new Long Person Period file has now `72` episodes, which is equals to `1440` when multiplied by `20`
```{r}
dtaPP %>% group_by(id, day) %>% summarise(max(Time))
72 * 20
```
<span class='newthought'>This post</span> will demonstrate how to simply calcualte mean time of different activities from a *wide format* dataset.
- Load the libraries and data
```{r, warning=FALSE, message=FALSE}
library(plyr)
library(dplyr)
library(tidyr)
library(mtusRlocal)
library(knitr)
library(reshape2)
library(xtable)
library('schoolmath')
dta = read.csv('/Users/giacomovagni/site/motsetchoses/_data/dtaSpells.csv')
```
```{r, results='asis', echo=FALSE}
kable(dta, align = 'c')
```
```{r}
dtaPP = dta[rep(1:nrow(dta), dta$duration), ] %>%
select(-duration) %>%
group_by(id, day) %>%
mutate( Time = 1:n())
```
Let's look at the first 10 entries
```{r, results='asis', echo=FALSE}
kable(dtaPP [1:10, ], align = 'c')
```
The maximum time per day is
```{r}
dtaPP %>% group_by(id, day) %>% summarise(max(Time))
```
which means that we have created a one minute interval dataset, known as **Long Person-Period**:
This code enables to transform the long file into a **Wide Sequence** file.
```{r}
dtaWide = dtaPP %>% select(-epnum) %>% spread(Time, activities)
```
The 10 first sequence episodes look like this :
```{r, results='asis', echo=FALSE}
kable( dtaWide [, 1:12] , align = 'c')
```
## Change the interval time
Find the greatest common divisor
```{r}
l = length(dta$duration)
v = array(0, l)
for(i in 2:l){
v[i] = gcd(dta$duration[i], dta$duration[i-1])
}
minV = min(v[-1])
dta$duration = dta$duration / minV
```
minV
dta
dtaPP = dta[rep(1:nrow(dta), dta$duration), ] %>%
select(-duration) %>%
group_by(id, day) %>%
mutate( Time = 1:n())
```
dtaPP %>% group_by(id, day) %>% summarise(max(Time))
dtaPP
dtaPP %>% group_by(id, day) %>% summarise(max(Time))
dtaPP
dtaPP %>% group_by(id, day) %>% summarise(max(Time))
72 * 20
servr::jekyll(command = '/Users/giacomovagni/.rvm/gems/ruby-2.2.1/wrappers/jekyll build')
servr::jekyll(command = '/Users/giacomovagni/.rvm/gems/ruby-2.2.1/wrappers/jekyll build')
servr::jekyll(command = '/Users/giacomovagni/.rvm/gems/ruby-2.2.1/wrappers/jekyll build')
dtaSeq
---
layout: post
title:  "Compute mean for activities - all format"
categories: [jekyll]
tags: [mtus]
---
<span class='newthought'>This post</span> will demonstrate how to simply calcualte mean time of different activities for different format.
```{r, warning=FALSE, message=FALSE}
# Load the libraries and data
library(plyr)
library(dplyr)
library(tidyr)
library(mtusRlocal)
library(knitr)
library(reshape2)
library(xtable)
dta = read.csv('/Users/giacomovagni/site/motsetchoses/_data/dtaSpells.csv')
```
### 1. Mean of Short PP file
The `sum` of all activites duration for each individuals for a day must be **1440**.
```{r}
dta %>% group_by(id, day) %>% summarise(sum(duration))
```
The individual mean can be computed such as :
```{r}
dta %>% group_by(id, activities) %>% summarise(mean(duration))
```
The aggregate mean by day :
```{r}
dta %>% group_by(day, activities) %>% summarise(mean(duration))
```
The aggregate mean by activities, regardless of the day :
```{r}
dta %>% group_by(activities) %>% summarise(mean(duration))
```
### 2. Mean of Long PP file
For Long PP file
```{r}
# transform
dtaPP= dta[rep(1:nrow(dta), dta$duration), ] %>%
select(-duration) %>%
group_by(id, day) %>%
mutate(Time = 1:n())
dtaPP %>% group_by(id, day, activities) %>% summarise(time = n()) %>% # transform back to short PP
group_by(activities, day) %>%
summarise(mean(time))
```
### 3. Mean of Sequence File
#### 3.1. Aggregate
The mean time of activities for long PP can be computed by the following codes :
```{r}
# transform PP to Wide
dtaSeq = dta[rep(1:nrow(dta), dta$duration), ] %>%
select(-duration) %>%
group_by(id, day) %>%
mutate(Time = 1:n()) %>% # PP
arrange(id, day, Time) %>% select(-epnum) %>% spread(Time, activities) # Wide
# colnames renames
colnames(dtaSeq) = c('idind', 'day', paste("main", 1:1440, sep = ""))
```
```{r}
N = count(dtaSeq)
N
# by act only
dtaSeq %>% select(idind, day, matches('main')) %>%
melt(id.vars = c("idind", "day")) %>% group_by(value) %>% summarise(n = n()) %>% # back to PP
mutate(time =  (n* 1) / 4 ) %>% # divide by count
mutate(TimeClock(time))
# by act and days
dtaSeq %>% select(idind, day, matches('main')) %>%
melt(id.vars = c("idind", "day")) %>% group_by(day, value) %>% summarise(n = n()) %>%
mutate(time =  (n* 1) / 2) %>% # divide by count
mutate(TimeClock(time))
# if you haev the full data then group by what you want
dtaSeq %>% select(idind, day, matches('main')) %>%
melt(id.vars = c("idind", "day")) %>% group_by(idind, day, value) %>% summarise(n = n()) %>%
group_by(value) %>% summarise( mean(n) )
mutate(TimeClock(time))
# or simply activities
dtaSeq %>% select(idind, day, matches('main')) %>%
melt(id.vars = c("idind", "day")) %>% group_by(idind, day, value) %>% summarise(n = n()) %>%
group_by(value, day) %>% summarise( mean(n) )
mutate(TimeClock(time))
dtaSeq
dtaSeq %>% select(idind, day, matches('main')) %>%
melt(id.vars = c("idind", "day"))
dtaSeq %>% select(idind, day, matches('main')) %>%
melt(id.vars = c("idind", "day")) %>% group_by(value) %>% summarise(n = n()) %>% # back to PP
mutate(p = n / sum(n))
dtaSeq %>% select(idind, day, matches('main')) %>%
melt(id.vars = c("idind", "day")) %>% group_by(value) %>% summarise(n = n()) %>% # back to PP
mutate(p = n / sum(n)) %>% mutate(time =  1440 * p)
dtaSeq %>% select(idind, day, matches('main')) %>%
melt(id.vars = c("idind", "day")) %>% group_by(value) %>% summarise(n = n()) %>% # back to PP
mutate(p = n / sum(n)) %>% mutate(time =  1440 * p) %>% # divide by count
mutate(TimeClock(time))
head(dtaPP)
dtaPP_sum
dtaPP_sum = dtaPP %>%
group_by(id, day, activities) %>%
summarise(n = n() * 1) %>% # multiply by the interval - here is 1 minutes
mutate(activities = paste('act_', activities, sep = '')) %>%
spread(activities, n, fill = 0)
dtaPP_sum
dtaSeq
dtaSeq$day
1 / 7
5 / 7
2 / 7
1 / (5 / 7)
1 / (2 / 7)
(5 / 7)
(2 / 7)
weekendproba = (2 / 7)
1 - weekendproba
dtaSeq$day %in% "Monday"
ifelse(dtaSeq$day %in% "Monday", 1, 1 - weekendproba)
dtaSeq$day_weights = ifelse(dtaSeq$day %in% "Monday", 1, 1 - weekendproba)
dtaSeq %>% select(idind, day, day_weights, matches('main'))
# kool - weighted mean
dtaSeq %>% select(idind, day, day_weights, matches('main')) %>%
melt(id.vars = c("idind", "day", "day_weights")) %>% group_by(idind, day, day_weights, value) %>% summarise(n = n())
# kool - weighted mean
dtaSeq %>% select(idind, day, day_weights, matches('main')) %>%
melt(id.vars = c("idind", "day", "day_weights")) %>% group_by(idind, day, day_weights, value) %>% summarise(n = n()) %>%
mutate(value = paste('act_', value, sep = '')) %>%
spread(value, n, fill = 0)
# Weighted mean
dtaSeq %>% select(idind, day, day_weights, matches('main')) %>%
melt(id.vars = c("idind", "day", "day_weights")) %>% group_by(idind, day, day_weights, value) %>% summarise(n = n()) %>%
mutate(value = paste('act_', value, sep = '')) %>%
spread(value, n, fill = 0) %>%
summarise(wmean = weighted.mean(act_1, day_weights), TimeClock(wmean))
# Weighted mean
dtaSeq %>% select(idind, day, day_weights, matches('main')) %>%
melt(id.vars = c("idind", "day", "day_weights")) %>% group_by(idind, day, day_weights, value) %>% summarise(n = n()) %>%
mutate(value = paste('act_', value, sep = '')) %>%
spread(value, n, fill = 0)
# Weighted mean
dtaSeq %>% select(idind, day, day_weights, matches('main')) %>%
melt(id.vars = c("idind", "day", "day_weights")) %>% group_by(idind, day, day_weights, value) %>% summarise(n = n()) %>%
mutate(value = paste('act_', value, sep = '')) %>%
spread(value, n, fill = 0) %>%
summarise(wmean = weighted.mean(act_TV, day_weights), TimeClock(wmean))
# Weighted mean
dtaSeq %>% select(idind, day, day_weights, matches('main')) %>%
melt(id.vars = c("idind", "day", "day_weights")) %>% group_by(idind, day, day_weights, value) %>% summarise(n = n()) %>%
mutate(value = paste('act_', value, sep = '')) %>%
spread(value, n, fill = 0) %>%
summarise(meanTV = mean(act_TV), wmeanTV = weighted.mean(act_TV, day_weights), TimeClock(wmean))
# Weighted mean
dtaSeq %>% select(idind, day, day_weights, matches('main')) %>%
melt(id.vars = c("idind", "day", "day_weights")) %>% group_by(idind, day, day_weights, value) %>% summarise(n = n()) %>%
mutate(value = paste('act_', value, sep = '')) %>%
spread(value, n, fill = 0)
# Weighted mean
dtaSeq %>% select(idind, day, day_weights, matches('main')) %>%
melt(id.vars = c("idind", "day", "day_weights")) %>% group_by(idind, day, day_weights, value) %>% summarise(n = n()) %>%
mutate(value = paste('act_', value, sep = '')) %>%
spread(value, n, fill = 0) %>%
summarise(meanTV = mean(act_TV), wmeanTV = weighted.mean(act_TV, day_weights), TimeClock(wmean))
# Weighted mean
dtaSeq %>% select(idind, day, day_weights, matches('main')) %>%
melt(id.vars = c("idind", "day", "day_weights")) %>% group_by(idind, day, day_weights, value) %>% summarise(n = n()) %>%
mutate(value = paste('act_', value, sep = '')) %>%
spread(value, n, fill = 0) %>%
summarise(meanTV = mean(act_TV), wmeanTV = weighted.mean(act_TV, day_weights))
dtaSeq %>% select(idind, day, day_weights, matches('main')) %>%
melt(id.vars = c("idind", "day", "day_weights")) %>%
group_by(idind, day, day_weights, value) %>%
summarise(n = n()) %>%
mutate(value = paste('act_', value, sep = '')) %>%
spread(value, n, fill = 0) %>%
summarise_each(funs(means), weighted.mean(w = day_weights))
# Weighted mean
dtaSeq %>% select(idind, day, day_weights, matches('main')) %>%
melt(id.vars = c("idind", "day", "day_weights")) %>%
group_by(idind, day, day_weights, value) %>%
summarise(n = n()) %>%
mutate(value = paste('act_', value, sep = '')) %>%
spread(value, n, fill = 0) %>%
summarise_each( funs(weighted.mean(w = day_weights)) )
# Weighted mean
dtaSeq %>% select(idind, day, day_weights, matches('main')) %>%
melt(id.vars = c("idind", "day", "day_weights")) %>%
group_by(idind, day, day_weights, value) %>%
summarise(n = n()) %>%
mutate(value = paste('act_', value, sep = '')) %>%
spread(value, n, fill = 0) %>%
summarise_each( funs(weighted.mean(,w = day_weights)) )
# Weighted mean
dtaSeq %>% select(idind, day, day_weights, matches('main')) %>%
melt(id.vars = c("idind", "day", "day_weights")) %>%
group_by(idind, day, day_weights, value) %>%
summarise(n = n()) %>%
mutate(value = paste('act_', value, sep = '')) %>%
spread(value, n, fill = 0) %>%
summarise_each(meanTV = mean(act_TV), weighted.mean(act_TV, day_weights))
# Weighted mean
dtaSeq %>% select(idind, day, day_weights, matches('main')) %>%
melt(id.vars = c("idind", "day", "day_weights")) %>%
group_by(idind, day, day_weights, value) %>%
summarise(n = n()) %>%
mutate(value = paste('act_', value, sep = '')) %>%
spread(value, n, fill = 0)
# Weighted mean
dtaSeq %>% select(idind, day, day_weights, matches('main')) %>%
melt(id.vars = c("idind", "day", "day_weights")) %>%
group_by(idind, day, day_weights, value) %>%
summarise(n = n()) %>%
mutate(value = paste('act_', value, sep = '')) %>%
spread(value, n, fill = 0) %>%
summarise(meanTV = mean(act_TV), weighted.mean(act_TV, day_weights))
# Weighted mean
dtaSeq %>% select(idind, day, day_weights, matches('main')) %>%
melt(id.vars = c("idind", "day", "day_weights")) %>%
group_by(idind, day, day_weights, value) %>%
summarise(n = n()) %>%
mutate(value = paste('act_', value, sep = '')) %>%
spread(value, n, fill = 0) %>%
summarise(meanTV = mean(act_TV), weightedmean = weighted.mean(act_TV, day_weights))
```
servr::jekyll(command = '/Users/giacomovagni/.rvm/gems/ruby-2.2.1/wrappers/jekyll build')
servr::jekyll(command = '/Users/giacomovagni/.rvm/gems/ruby-2.2.1/wrappers/jekyll build')
servr::jekyll(command = '/Users/giacomovagni/.rvm/gems/ruby-2.2.1/wrappers/jekyll build')
dta
dta %>% count(sex)
dta %>% count(day)
dta %>% count(day, wt = weekendproba)
```{r}
# weights of weekdays
weekendproba = (2 / 7)
# weights - 1 is weekdays
dtaSeq$day_weights = ifelse(dtaSeq$day %in% "Monday", 1, 1 - weekendproba)
# Weighted mean
dtaSeq %>% select(idind, day, day_weights, matches('main')) %>%
melt(id.vars = c("idind", "day", "day_weights")) %>%
group_by(idind, day, day_weights, value) %>%
summarise(n = n()) %>%
mutate(value = paste('act_', value, sep = '')) %>%
spread(value, n, fill = 0) %>%
summarise(meanTV = mean(act_TV), weightedmean = weighted.mean(act_TV, day_weights))
```
dta %>% count(day, wt = weekendproba)
weekendproba
dta %>% count(day, wt = day_weights)
dtaSeq %>% count(day, wt = day_weights)
dtaSeq
dtaSeq %>% count(day, wt = day_weights)
dtaSeq %>% count(day, wt = day_weights) %>% mutate(n / sum(n))
dtaSeq %>% count(day) %>% mutate(n = n / sum(n))
dtaSeq %>% count(day) %>% mutate(n = n / sum(n))
dtaSeq %>% count(day, wt = day_weights) %>% mutate(n = n / sum(n))
dtaSeq %>% count(day) %>% mutate(n = n / sum(n))
dtaSeq %>% count(day) %>% mutate(n = n / sum(n))
dtaSeq %>% count(day, wt = day_weights) %>% mutate(p = n / sum(n))
dtaSeq %>% count(day) %>% mutate(p = n / sum(n))
dtaSeq %>% count(day, wt = day_weights) %>% mutate(p = n / sum(n))
servr::jekyll(command = '/Users/giacomovagni/.rvm/gems/ruby-2.2.1/wrappers/jekyll build')
